---
title: "Author_Attribution"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tm) 
library(tidyverse)
library(slam)
library(proxy)
library(e1071)
library(caret)
library(randomForest)
```

```{r, include = FALSE}
#Reading all Folders
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), 
            id=fname, language='en') 
}
```

#In this section, we are processing the training data to eliminate stop words, removing punctuations, make terms lowercase and more. The end result is a document term matrix with tf-idf weights.
```{r}
#set up train
train=Sys.glob('ReutersC50/C50train/*')

#get all the files
file_list = NULL
labels = NULL
for(author in train) {
  author_name = strsplit(author, "/")[[1]][3]
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  labels = append(labels, rep(author_name, length(files_to_add)))
}

all_docs = lapply(file_list, readerPlain)
#clean up file names
mynames = train %>%
  { strsplit(., '/', fixed=TRUE) } %>%
  { lapply(., tail, n=2) } %>%
  { lapply(., paste0, collapse = '') } %>%
  unlist

#Rename the articles
names(all_docs) = mynames

#create a text mining "corpus
documents_raw = Corpus(VectorSource(all_docs))

#some pre-process
my_documents = documents_raw %>%
  tm_map(content_transformer(tolower))  %>%             # make everything lowercase
  tm_map(content_transformer(removeNumbers)) %>%        # remove numbers
  tm_map(content_transformer(removePunctuation)) %>%    # remove punctuation
  tm_map(content_transformer(stripWhitespace))          # remove excess white-space

#remove the stopwords
my_documents = tm_map(my_documents, content_transformer(removeWords), stopwords("en"))

## create a doc-term-matrix from the corpus
DTM_train = DocumentTermMatrix(my_documents)
DTM_train # some basic summary statistics
DTM_train = removeSparseTerms(DTM_train, 0.95) #removes those terms that have count 0 in >95% of docs.  
DTM_train # now ~ 804 terms (versus ~32000 before)
col_train = colnames(DTM_train)
# construct TF IDF weights -- might be useful if we wanted to use these
# as features in a predictive model
tfidf_train = weightTfIdf(DTM_train)
DTM_train <- as.matrix(tfidf_train)
tfidf_train
```

#In this section, we do the same processing step we did for the training set to the testing set. 
```{r}
#Repeat for test
#set up test
test=Sys.glob('ReutersC50/C50test/*')

#get all the files
file_list1 = NULL
labels1 = NULL
for(author in test) {
  author_name1 = strsplit(author, "/")[[1]][3]
  files_to_add1 = Sys.glob(paste0(author, '/*.txt'))
  file_list1 = append(file_list1, files_to_add1)
  labels1 = append(labels1, rep(author_name1, length(files_to_add1)))
}

all_docs1 = lapply(file_list1, readerPlain)
#clean up file names
mynames1 = train %>%
  { strsplit(., '/', fixed=TRUE) } %>%
  { lapply(., tail, n=2) } %>%
  { lapply(., paste0, collapse = '') } %>%
  unlist

#Rename the articles
names(all_docs1) = mynames1

#create a text mining "corpus
documents_raw1 = Corpus(VectorSource(all_docs1))

#some pre-process
my_documents1 = documents_raw1 %>%
  tm_map(content_transformer(tolower))  %>%             # make everything lowercase
  tm_map(content_transformer(removeNumbers)) %>%        # remove numbers
  tm_map(content_transformer(removePunctuation)) %>%    # remove punctuation
  tm_map(content_transformer(stripWhitespace))          # remove excess white-space

#remove the stopwords
my_documents1 = tm_map(my_documents1, content_transformer(removeWords), stopwords("en"))

## create a doc-term-matrix from the corpus
DTM_test = DocumentTermMatrix(my_documents1)
DTM_test # some basic summary statistics
DTM_test = removeSparseTerms(DTM_test, 0.95) #removes those terms that have count 0 in >95% of docs.  
DTM_test # now ~ 819 terms (versus ~32000 before)
```

#Here we are getting rid of all the words that are in the testing set but not in the training set and make the two matrix the same length. 
```{r}
#Since train and test are different lengths, make the test length the same as the train 
#Construct TFIDF for test
DTM_test=DocumentTermMatrix(my_documents1,list(dictionary=colnames(DTM_train)))
tfidf_test = weightTfIdf(DTM_test)
DTM_test<-as.matrix(tfidf_test) #Matrix
tfidf_test #804 terms
```

#In this section, we are trying to reduce the dimensions using PCA. We found that at PC159, around 50% of the variance is explained, therefore we use that as a cutoff for the number of features(PC) we pass in to our model. 
```{r}
####
# Dimensionality reduction
####
DTM_train_1 <- DTM_train[,which(colSums(DTM_train) != 0)] 
DTM_test_1 <- DTM_test[,which(colSums(DTM_test) != 0)]
```

```{r}
#PCA
pca_tr = prcomp(DTM_train_1,scale=TRUE)
pred_pca=predict(pca_tr,newdata = DTM_test_1)
plot(pca_tr,type='line')
plot(cumsum(pca_tr$sdev^2/sum(pca_tr$sdev^2)))
summary(pca_tr)$importance[,159]
#Majority (50%) var explained at PC159 so lets use that

pca_ts = prcomp(DTM_test_1,scale=TRUE)

```
#In this section, we tried different kinds of model for classfying the documents. The random forest model had the highest accuracy which is around 75%
```{r}
#Classification techniques 

#classification setup
tr = data.frame(pca_tr$x[,1:159]) #x-variables
tr['labels']=labels #y-variable
ts <- data.frame(pca_ts$x[,1:159]) #x-variables
ts['labels1']=as.factor(labels1) #y-variable
```

```{r}
#Naive-Bayes

set.seed(848484)
nbay = naiveBayes(formula = as.factor(labels) ~ ., data = tr, 
                  laplace = 1)
pred_nbay = predict(nbay, ts, type="class")
confusionMatrix(pred_nbay,ts$labels1)$overall['Accuracy']
#1.9% accuracy, therefore its a bad model and we want to move on to another modeling technique
```

```{r}
#Random Forest Technique

set.seed(848484)
rf<-randomForest(as.factor(labels)~.,data=tr, mtry=5,importance=TRUE)
pred_rf<-predict(rf,data=ts,type="class")
confusionMatrix(pred_rf,ts$labels1)$overall['Accuracy']
#74.56%, the Random Forest model is the best model we found.
```



